{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minecraft1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "interpreter": {
      "hash": "b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikros98/Minecraft-settlement-GAN/blob/main/minecraft_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7LwZN1CZ-yr"
      },
      "source": [
        "# code for GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/FProject')\n",
        "folder = '/content/gdrive/MyDrive/FProject/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARKoPNG5wJO8"
      },
      "source": [
        "# auto reload\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn7NxPcARcPx",
        "outputId": "6c47009d-ea9c-407f-f48f-a5b90c424082"
      },
      "source": [
        "!pip install nbtlib\n",
        "!git clone https://ikros98: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@github.com/ikros98/Minecraft-settlement-GAN.git\n",
        "%cd Minecraft-settlement-GAN/\n",
        "#import sys\n",
        "#sys.path.append('/content/Minecraft-settlement-GAN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nbtlib\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/0e/b1299899ff764ff40344db572fffaf70b1bc64b44ac8cc7084dd5a5ef0d1/nbtlib-1.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy<2.0,>=1.16 in /usr/local/lib/python3.7/dist-packages (from nbtlib) (1.19.5)\n",
            "Installing collected packages: nbtlib\n",
            "Successfully installed nbtlib-1.7.0\n",
            "Cloning into 'Minecraft-settlement-GAN'...\n",
            "remote: Enumerating objects: 3280, done.\u001b[K\n",
            "remote: Counting objects: 100% (3280/3280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3185/3185), done.\u001b[K\n",
            "remote: Total 3280 (delta 232), reused 3141 (delta 94), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3280/3280), 12.61 MiB | 34.53 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n",
            "/content/Minecraft-settlement-GAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKFD6ceJGW2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe684e29-b32c-4090-e5af-67858484f960"
      },
      "source": [
        "%cd Minecraft-settlement-GAN/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'Minecraft-settlement-GAN/'\n",
            "/content/Minecraft-settlement-GAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPrDfxso_EdK",
        "outputId": "bce5d6da-c405-4b54-f5a7-06b6342bb1a9"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6 (delta 3), reused 6 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  16% (1/6)   \rUnpacking objects:  33% (2/6)   \rUnpacking objects:  50% (3/6)   \rUnpacking objects:  66% (4/6)   \rUnpacking objects:  83% (5/6)   \rUnpacking objects: 100% (6/6)   \rUnpacking objects: 100% (6/6), done.\n",
            "From https://github.com/ikros98/Minecraft-settlement-GAN\n",
            "   759601f..84024ba  main       -> origin/main\n",
            "Updating 759601f..84024ba\n",
            "Fast-forward\n",
            " .DS_Store                                           | Bin \u001b[31m10244\u001b[m -> \u001b[32m10244\u001b[m bytes\n",
            " mcedit settlement generator/.DS_Store               | Bin \u001b[31m6148\u001b[m -> \u001b[32m6148\u001b[m bytes\n",
            " mcedit settlement generator/0.schematic             | Bin \u001b[31m394019\u001b[m -> \u001b[32m6568\u001b[m bytes\n",
            " .../sampledExample.schematic                        | Bin \u001b[31m384124\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " 4 files changed, 0 insertions(+), 0 deletions(-)\n",
            " mode change 100644 => 100755 mcedit settlement generator/0.schematic\n",
            " delete mode 100644 mcedit settlement generator/sampledExample.schematic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EefohfYwJO-"
      },
      "source": [
        "# colab\n",
        "folder = '/content/Minecraft-settlement-GAN/'\n",
        "# local\n",
        "#folder = '/Users/ikros/Documents/GitHub/Minecraft-settlement-GAN/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLbL-0kQwJO_"
      },
      "source": [
        "import SchematicTools\n",
        "from schematic import SchematicFile\n",
        "import numpy as np\n",
        "import SchematicTools\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBKoSbs23tNQ"
      },
      "source": [
        "My prova"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Bb6y6Fc37T"
      },
      "source": [
        "# this cleans transforms all the cubes in concrete\n",
        "simpleWorlds = SchematicTools.simplify(SchematicTools.loadArea(folder + 'mcedit settlement generator/0.schematic'))\n",
        "#exporting after simpleWorlds became\n",
        "exportSchematic = SchematicFile(shape=simpleWorlds.shape)\n",
        "exportSchematic.blocks = simpleWorlds\n",
        "exportSchematic.save(folder + \"mcedit settlement generator/sampledExample.schematic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c83-hsgU6nGL"
      },
      "source": [
        "My prova 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWzVepS46pY8"
      },
      "source": [
        "# it cleans the file from unnecessary blocks\n",
        "simpleWorlds = SchematicTools.simplify2(SchematicTools.loadArea(folder + 'mcedit settlement generator/0.schematic'))\n",
        "#exporting after simpleWorlds became\n",
        "exportSchematic = SchematicFile(shape=simpleWorlds.shape)\n",
        "exportSchematic.blocks = simpleWorlds\n",
        "exportSchematic.save(folder + \"mcedit settlement generator/sampledExample.schematic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83M4laLdwJPA"
      },
      "source": [
        "# cleaning all the schematics file from not useful \n",
        "for file in os.listdir(folder + \"dataset808020/\"):\n",
        "    settlement = SchematicTools.simplify2(SchematicTools.loadArea(folder + \"dataset808020/\" + file))\n",
        "    exportSchematic = SchematicFile(shape=settlement.shape)\n",
        "    exportSchematic.blocks = settlement\n",
        "    exportSchematic.save(folder + \"clean dataset/\" + file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI_U3paZwJPA"
      },
      "source": [
        "# creating a csv file with the cleaned settlements\n",
        "l = []\n",
        "for file in os.listdir(folder + \"clean dataset/\"):\n",
        "    settlement = SchematicTools.loadArea(folder + \"clean dataset/\" + file)\n",
        "    l.append(settlement.ravel())\n",
        "dataset = pd.DataFrame(l)\n",
        "dataset.to_csv('out.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0kBe5wxwJPB"
      },
      "source": [
        "# function to load the entire dataset\n",
        "def load_dataset():\n",
        "    l = []\n",
        "    for file in os.listdir(folder + \"clean dataset/\"):\n",
        "        settlement = SchematicTools.loadArea(folder + \"clean dataset/\" + file)\n",
        "        l.append(settlement)\n",
        "    x = np.array(l)\n",
        "    return (x)\n",
        "X = load_dataset()\n",
        "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1) #?? to fix float 32, maybe int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69exbSCI0IOm",
        "outputId": "540b787d-959c-4c40-c21d-ddc04f355916"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 30, 80, 80, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kn6wlFP3tlg"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "# have to understand how to manage the 30 that becomes 28\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(5*20*20*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((5, 20, 20, 256)))\n",
        "    assert model.output_shape == (None, 5, 20, 20, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv3DTranspose(128, (5, 5, 5), strides=(1, 1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 5, 20, 20, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv3DTranspose(64, (5, 5, 5), strides=(2, 2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 10, 40, 40, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv3DTranspose(1, (5, 5, 5), strides=(2, 2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 20, 80, 80, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv3D(64, (5, 5, 5), strides=(2, 2, 2), padding='same',\n",
        "                                     input_shape=[20, 80, 80, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv3D(128, (5, 5, 5), strides=(2, 2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5XSkcKF3BQy",
        "outputId": "129b2027-cefe-41c3-9c12-f2f1e9d9ab75"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "generated_image = generator(noise, training=False)\n",
        "\"\"\"\n",
        "#plt.imshow(generated_image[0, :, :, :, 0], cmap='gray')\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "def make_ax(grid=False):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.gca(projection='3d')\n",
        "    ax.set_xlabel(\"x\")\n",
        "    ax.set_ylabel(\"y\")\n",
        "    ax.set_zlabel(\"z\")#\n",
        "    ax.grid(grid)\n",
        "    return ax\n",
        "\n",
        "ax = make_ax(True)\n",
        "ax.voxels(generated_image[0, :, :, :, 0], edgecolors='gray', shade=False)\n",
        "plt.show()\"\"\"\n",
        "\n",
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)\n",
        "\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "EPOCHS = 250\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    #clear_output(wait=True)\n",
        "    #generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "    # Save the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "\n",
        "  preview = np.empty((0, 80 * example_grid,3), np.uint8)\n",
        "  for i in range(example_grid):\n",
        "      row = np.empty((80, 0, 3), np.uint8)\n",
        "      for j in range(example_grid):\n",
        "          imageR = predictions[i*example_grid + j, :, :, :, 0] * 127.5 + 127.5\n",
        "          imageG = np.average(imageR, axis=0)\n",
        "          image = np.stack((imageR[0], imageG, imageG), axis=2)\n",
        "          row = np.hstack((row, image))\n",
        "      preview = np.vstack((preview, row))\n",
        "\n",
        "  outputimage = PIL.Image.fromarray(preview.astype(np.uint8))\n",
        "  outputimage.save('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  return outputimage\n",
        "\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-3.8721228e-05]\n",
            " [-1.1065065e-04]\n",
            " [-5.2141208e-05]\n",
            " [-1.6891178e-04]\n",
            " [-1.1278138e-04]\n",
            " [-1.0857244e-04]\n",
            " [-1.7839907e-04]\n",
            " [ 2.5957732e-05]\n",
            " [ 4.5876815e-05]\n",
            " [ 6.6600151e-06]\n",
            " [-1.6903381e-05]\n",
            " [ 7.0180729e-05]\n",
            " [ 6.2339959e-06]\n",
            " [-1.7459079e-04]\n",
            " [-4.1941283e-05]\n",
            " [-2.0407180e-05]], shape=(16, 1), dtype=float32)\n",
            "Time for epoch 1 is 26.094701290130615 sec\n",
            "Time for epoch 2 is 26.17010998725891 sec\n",
            "Time for epoch 3 is 25.952904224395752 sec\n",
            "Time for epoch 4 is 25.27399444580078 sec\n",
            "Time for epoch 5 is 29.375288009643555 sec\n",
            "Time for epoch 6 is 24.74080491065979 sec\n",
            "Time for epoch 7 is 25.708856105804443 sec\n",
            "Time for epoch 8 is 25.630493640899658 sec\n",
            "Time for epoch 9 is 25.33682107925415 sec\n",
            "Time for epoch 10 is 29.319478034973145 sec\n",
            "Time for epoch 11 is 24.638949632644653 sec\n",
            "Time for epoch 12 is 25.674129724502563 sec\n",
            "Time for epoch 13 is 25.617865324020386 sec\n",
            "Time for epoch 14 is 25.584609270095825 sec\n",
            "Time for epoch 15 is 29.460440397262573 sec\n",
            "Time for epoch 16 is 24.988534212112427 sec\n",
            "Time for epoch 17 is 25.676183700561523 sec\n",
            "Time for epoch 18 is 25.928955554962158 sec\n",
            "Time for epoch 19 is 25.165040254592896 sec\n",
            "Time for epoch 20 is 29.401898860931396 sec\n",
            "Time for epoch 21 is 24.74681520462036 sec\n",
            "Time for epoch 22 is 26.399489164352417 sec\n",
            "Time for epoch 23 is 24.836857080459595 sec\n",
            "Time for epoch 24 is 25.539900302886963 sec\n",
            "Time for epoch 25 is 29.49360752105713 sec\n",
            "Time for epoch 26 is 24.69710350036621 sec\n",
            "Time for epoch 27 is 25.63583755493164 sec\n",
            "Time for epoch 28 is 25.526420831680298 sec\n",
            "Time for epoch 29 is 25.471272230148315 sec\n",
            "Time for epoch 30 is 29.385396003723145 sec\n",
            "Time for epoch 31 is 24.75702691078186 sec\n",
            "Time for epoch 32 is 25.656057834625244 sec\n",
            "Time for epoch 33 is 25.505300521850586 sec\n",
            "Time for epoch 34 is 25.49045491218567 sec\n",
            "Time for epoch 35 is 29.48909592628479 sec\n",
            "Time for epoch 36 is 24.837637186050415 sec\n",
            "Time for epoch 37 is 25.694384813308716 sec\n",
            "Time for epoch 38 is 25.491228103637695 sec\n",
            "Time for epoch 39 is 25.449880361557007 sec\n",
            "Time for epoch 40 is 29.505175828933716 sec\n",
            "Time for epoch 41 is 24.867611408233643 sec\n",
            "Time for epoch 42 is 25.684249877929688 sec\n",
            "Time for epoch 43 is 25.551007747650146 sec\n",
            "Time for epoch 44 is 25.484039306640625 sec\n",
            "Time for epoch 45 is 29.42094659805298 sec\n",
            "Time for epoch 46 is 24.84853982925415 sec\n",
            "Time for epoch 47 is 25.693222999572754 sec\n",
            "Time for epoch 48 is 25.51635241508484 sec\n",
            "Time for epoch 49 is 25.528541088104248 sec\n",
            "Time for epoch 50 is 29.565563201904297 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uGyg6RmcW0q"
      },
      "source": [
        "def jpp(vec, vals):\n",
        "    ss = np.searchsorted(vals, vec)\n",
        "    a = vals[ss - 1]\n",
        "    b = vals[np.minimum(len(vals) - 1, ss)]\n",
        "    return np.where(np.fabs(vec - a) < np.fabs(vec - b), a, b)\n",
        "\n",
        "world = SchematicTools.simplify2(SchematicTools.loadArea(folder + 'mcedit settlement generator/0.schematic'))\n",
        "blocks_type = np.unique(world.flatten())\n",
        "\n",
        "prova = generator(seed, training=False)\n",
        "prova = prova[0, :, :, :, 0].numpy().astype(int)\n",
        "prova = jpp(prova.flatten(), blocks_type)\n",
        "prova.reshape(20, 80, 80)\n",
        "#exportSchematic = SchematicFile(shape=prova.shape)\n",
        "#exportSchematic.blocks = prova\n",
        "#exportSchematic.save(folder + \"mcedit settlement generator/first trial clean.schematic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86BByLcXyeL5",
        "outputId": "5082433a-40b3-46c0-bb10-1a956f9dd605"
      },
      "source": [
        "np.unique(prova.flatten())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "EX28w08HxMQP",
        "outputId": "7103f131-4f15-41c6-8ec3-31cc2e63cac0"
      },
      "source": [
        "prova = generator(seed, training=False)\n",
        "prova = prova[0, :, :, :, 0].numpy().astype(int)\n",
        "np.searchsorted(prova, blocks_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-13f9539b7aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprova\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprova\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprova\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprova\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \"\"\"\n\u001b[0;32m-> 1343\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'searchsorted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: object too deep for desired array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpxdQM2EwXbI",
        "outputId": "35d0d7ba-f56d-414e-d808-79deb838965d"
      },
      "source": [
        "np.unique(prova.flatten())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsUlsz3nmWWz"
      },
      "source": [
        "from SchematicTools import asBoolean\n",
        "prova = generator(seed, training=False)\n",
        "prova = prova[0, :, :, :, 0].numpy().astype(np.uint8)#asBoolean??\n",
        "exportSchematic = SchematicFile(shape=prova.shape)\n",
        "exportSchematic.blocks = prova\n",
        "exportSchematic.save(folder + \"mcedit settlement generator/first trial.schematic\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCzGQ_JEzivh",
        "outputId": "9f44d7bb-ab0d-4c29-ec89-0d96a7aecf59"
      },
      "source": [
        "prova = generator(seed, training=False)\n",
        "prova = prova[0, :, :, :, 0].numpy()\n",
        "np.unique(prova.flatten())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.       , -0.9999999, -0.9999998, ...,  0.9999998,  0.9999999,\n",
              "        1.       ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3loY8kmfZhfm",
        "outputId": "53303f1c-63bf-4bb1-c1bd-df8eefddd379"
      },
      "source": [
        "#??\n",
        "samples = np.empty((0, SAMPLESIZE, SAMPLESIZE, SAMPLESIZE))\n",
        "for s in simpleWorlds :\n",
        "    samples = np.concatenate((samples, sample(s, SAMPLECOUNT, SAMPLESIZE)), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sampled (100000, 8, 8, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}