{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minecraft1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "interpreter": {
      "hash": "b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7LwZN1CZ-yr"
      },
      "source": [
        "# code for GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/FProject')\n",
        "folder = '/content/gdrive/MyDrive/FProject/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# auto reload\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn7NxPcARcPx",
        "outputId": "ec6667e7-e8a6-480d-e914-c96dceb92efa"
      },
      "source": [
        "!pip install nbtlib\n",
        "!git clone https://ikros98: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@github.com/ikros98/Minecraft-settlement-GAN.git\n",
        "%cd Minecraft-settlement-GAN/\n",
        "#import sys\n",
        "#sys.path.append('/content/Minecraft-settlement-GAN')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nbtlib in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16 in /usr/local/lib/python3.7/dist-packages (from nbtlib) (1.19.5)\n",
            "Cloning into 'Minecraft-settlement-GAN'...\n",
            "remote: Enumerating objects: 238, done.\u001b[K\n",
            "remote: Counting objects: 100% (238/238), done.\u001b[K\n",
            "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
            "remote: Total 238 (delta 5), reused 238 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (238/238), 1.32 MiB | 7.79 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "/content/Minecraft-settlement-GAN/Minecraft-settlement-GAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKFD6ceJGW2f"
      },
      "source": [
        "%cd Minecraft-settlement-GAN/"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPrDfxso_EdK",
        "outputId": "bce5d6da-c405-4b54-f5a7-06b6342bb1a9"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 6 (delta 3), reused 6 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  16% (1/6)   \rUnpacking objects:  33% (2/6)   \rUnpacking objects:  50% (3/6)   \rUnpacking objects:  66% (4/6)   \rUnpacking objects:  83% (5/6)   \rUnpacking objects: 100% (6/6)   \rUnpacking objects: 100% (6/6), done.\n",
            "From https://github.com/ikros98/Minecraft-settlement-GAN\n",
            "   759601f..84024ba  main       -> origin/main\n",
            "Updating 759601f..84024ba\n",
            "Fast-forward\n",
            " .DS_Store                                           | Bin \u001b[31m10244\u001b[m -> \u001b[32m10244\u001b[m bytes\n",
            " mcedit settlement generator/.DS_Store               | Bin \u001b[31m6148\u001b[m -> \u001b[32m6148\u001b[m bytes\n",
            " mcedit settlement generator/0.schematic             | Bin \u001b[31m394019\u001b[m -> \u001b[32m6568\u001b[m bytes\n",
            " .../sampledExample.schematic                        | Bin \u001b[31m384124\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " 4 files changed, 0 insertions(+), 0 deletions(-)\n",
            " mode change 100644 => 100755 mcedit settlement generator/0.schematic\n",
            " delete mode 100644 mcedit settlement generator/sampledExample.schematic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# colab\n",
        "# folder = '/content/Minecraft-settlement-GAN/'\n",
        "# local\n",
        "folder = '/Users/ikros/Documents/GitHub/Minecraft-settlement-GAN/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import SchematicTools\n",
        "from schematic import SchematicFile\n",
        "import numpy as np\n",
        "import SchematicTools\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBKoSbs23tNQ"
      },
      "source": [
        "My prova"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Bb6y6Fc37T"
      },
      "source": [
        "# this cleans transforms all the cubes in concrete\n",
        "simpleWorlds = SchematicTools.simplify(SchematicTools.loadArea(folder + 'mcedit settlement generator/0.schematic'))\n",
        "#exporting after simpleWorlds became\n",
        "exportSchematic = SchematicFile(shape=simpleWorlds.shape)\n",
        "exportSchematic.blocks = simpleWorlds\n",
        "exportSchematic.save(folder + \"mcedit settlement generator/sampledExample.schematic\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c83-hsgU6nGL"
      },
      "source": [
        "My prova 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "dWzVepS46pY8",
        "outputId": "45c24367-4a65-47f9-d249-cb7c066e8acc"
      },
      "source": [
        "# it cleans the file from unnecessary blocks\n",
        "simpleWorlds = SchematicTools.simplify2(SchematicTools.loadArea(folder + 'mcedit settlement generator/0.schematic'))\n",
        "#exporting after simpleWorlds became\n",
        "exportSchematic = SchematicFile(shape=simpleWorlds.shape)\n",
        "exportSchematic.blocks = simpleWorlds\n",
        "exportSchematic.save(folder + \"mcedit settlement generator/sampledExample.schematic\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cleaning all the schematics file from not useful \n",
        "for file in os.listdir(folder + \"dataset808030/\"):\n",
        "    settlement = SchematicTools.simplify2(SchematicTools.loadArea(folder + \"dataset808030/\" + file))\n",
        "    exportSchematic = SchematicFile(shape=settlement.shape)\n",
        "    exportSchematic.blocks = settlement\n",
        "    exportSchematic.save(folder + \"clean dataset/\" + file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating a csv file with the cleaned settlements\n",
        "l = []\n",
        "for file in os.listdir(folder + \"clean dataset/\"):\n",
        "    settlement = SchematicTools.loadArea(folder + \"clean dataset/\" + file)\n",
        "    l.append(settlement.ravel())\n",
        "dataset = pd.DataFrame(l)\n",
        "dataset.to_csv('out.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to load the entire dataset\n",
        "def load_dataset():\n",
        "    l = []\n",
        "    for file in os.listdir(folder + \"clean dataset/\"):\n",
        "        settlement = SchematicTools.loadArea(folder + \"clean dataset/\" + file)\n",
        "        l.append(settlement)\n",
        "    x = np.array(l)\n",
        "    return (x)\n",
        "X = load_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "\n",
        "import modelGAN\n",
        "\n",
        "## Train a GAN to create 8x8 chunks of Minecraft buildings.\n",
        "\n",
        "tf.executing_eagerly()\n",
        "\n",
        "BUFFER_SIZE = 90000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "EPOCHS = 20\n",
        "EPOCH_EXPORT_STEP = 10\n",
        "EPOCH_IMAGE_STEP = 10\n",
        "noise_dim = 100\n",
        "example_grid = 10\n",
        "num_examples_to_generate = example_grid**2\n",
        "\n",
        "X = load_dataset():\n",
        "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], X.shape[3], 1).astype('float32')\n",
        "X = X * 2 - 1 #??????\n",
        "\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(X).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "generator = modelGAN.make_generator_model(BASE)\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "discriminator = modelGAN.make_discriminator_model(BASE)\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)\n",
        "\n",
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "checkpoint_dir = './training_checkpoints_%dx' % X.shape[3]\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images\n",
        "    if (epoch % EPOCH_IMAGE_STEP == 0) :\n",
        "        generate_and_save_images(generator,\n",
        "                                epoch + 1,\n",
        "                                seed)\n",
        "    if (epoch % EPOCH_EXPORT_STEP == 0) :\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed).show()\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "\n",
        "  preview = np.empty((0, B3 * example_grid,3), np.uint8)\n",
        "  for i in range(example_grid):\n",
        "      row = np.empty((B3, 0, 3), np.uint8)\n",
        "      for j in range(example_grid):\n",
        "          imageR = predictions[i*example_grid + j, :, :, :, 0] * 127.5 + 127.5\n",
        "          imageG = np.average(imageR, axis=0)\n",
        "          image = np.stack((imageR[0], imageG, imageG), axis=2)\n",
        "          row = np.hstack((row, image))\n",
        "      preview = np.vstack((preview, row))\n",
        "\n",
        "  outputimage = PIL.Image.fromarray(preview.astype(np.uint8))\n",
        "  outputimage.save('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  return outputimage\n",
        "\n",
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3loY8kmfZhfm",
        "outputId": "53303f1c-63bf-4bb1-c1bd-df8eefddd379"
      },
      "source": [
        "#??\n",
        "samples = np.empty((0, SAMPLESIZE, SAMPLESIZE, SAMPLESIZE))\n",
        "for s in simpleWorlds :\n",
        "    samples = np.concatenate((samples, sample(s, SAMPLECOUNT, SAMPLESIZE)), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sampled (100000, 8, 8, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}